<style>
p {
  text-indent: 20px;
}
li {
  text-indent: 20px;
}
</style>

<h1>Bayes Estimation</h1> 


The animation (generated with  <a href="http://www.cinderella.de">Cinderella</a>) shows the Bayes estimation of a single parameter from a single observation.
    
<p> Bayes estimation is a well-established method for information fusion based on a probabilistic setup. The parameter &theta; is to be estimated. The prior information is encoded by the density p(&theta;). In addition we have the observation y, which is related to the parameter &theta; by the likelihood function L(&theta;)=p(y|&theta;). It is the conditional probability density for y given some value &theta; and tells how likely some value &theta; is, if an observational value is given.  Bayes' theorem provides the a posteriori density p(&theta;|y)=p(&theta;)p(y|&theta;)/p(y). A maximum a posteriori estimate then is the maximum of this density. </p>

<p> The example shown below assumes the prior density is a mixture of two Gaussians with the same standard deviation &sigma;=0.1, the means &mu;<sub>1</sub> and &mu;<sub>2</sub>, and the probabilities P<sub>1</sub>=P(&mu;= &mu;<sub>1</sub>) and P<sub>2</sub>=1-P<sub>1</sub>.  The observation with (a usually high) probability P<sub>in</sub> is an inlier with a standard deviation of &sigma;<sub>y</sub>. Otherwise it is assumed to be an outlier, randomly lying in the interval [0,3]. </p>

<p> You can interactively change (1) the two mean values &mu;<sub>1</sub> and &mu;<sub>2</sub>  by shifting the lower red points to the left or the right, (2) the prior probability P<sub>1</sub> for the mean  &mu;<sub>1</sub> by shifting the left red point up or down, enforcing P<sub>1</sub>&#8712;[0,1], (3) the probability P<sub>in</sub> by shifting the left blue point up or down, again enforcing P<sub>in</sub>&#8712;[0,1], (4) the observational value y by shifting the lower blue point to the left or the right, and its standard deviation &sigma;<sub>y</sub> (being the distance to the ordinate axis) by shifting the lower left blue point to the right or left.</p> 

    
<p> Depending on the chosen values, the applet then shows (1) the prior density p(&theta;) as red curve, (2) the likelihood  L(&theta;)=p(y|&theta;) as dashed blue curve, and (3) the resulting posterior density p(&theta;|y) as the green curve. The initial configuration assumes the means are  &mu;<sub>1</sub>=1.2 and &mu;<sub>2</sub>=1.6, the mean &mu;<sub>1</sub> is slightly more probable than the mean &mu;<sub>2</sub>, namely P<sub>1</sub>=0.55, the inlier rate is P<sub>in</sub>=90&#37;, and the observational value is y=1.5. All values are shown with two digits. </p>
    

    <h2>Explore the configuration:</h2>
    <ul>
      <li> - Change each of the values individually and explore the effect onto the three functions, and especially onto the maximum of the posterior density p(&theta;|y). </li>
 			
 			<li> - Choose P<sub>in</sub>=90&#37;, and explore the effect of the other free parameters. Compare the effect of y onto the maximum of the posterior density p(&theta;|y).</li>

                       <li> - Choose &mu;<sub>1</sub>=&mu;<sub>2</sub> and explore the effect of the other free parameters. </li>
 			
	    <li> - Can you find a case where the posterior density has three relative maxima of the same density value? Explain the situation. </li>
	        </ul>
